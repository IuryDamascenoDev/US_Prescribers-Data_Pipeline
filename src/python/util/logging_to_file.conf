[loggers]
keys = root, create_spark_objects, validations, data_ingest, data_preprocessor, data_transform, data_export

[handlers]
keys = file_handler

[formatters]
keys = file_formatter

[logger_root]
level = DEBUG
handlers = file_handler

[logger_create_spark_objects]
level = DEBUG
handlers = file_handler
qualname = create_spark_objects
propagate = 0

[logger_validations]
level = DEBUG
handlers = file_handler
qualname = validations
propagate = 0

[logger_data_ingest]
level = DEBUG
handlers = file_handler
qualname = data_ingest
propagate = 0

[logger_data_preprocessor]
level = DEBUG
handlers = file_handler
qualname = data_preprocessor
propagate = 0

[logger_data_transform]
level = DEBUG
handlers = file_handler
qualname = data_transform
propagate = 0

[logger_data_export]
level = DEBUG
handlers = file_handler
qualname = data_export
propagate = 0

[handler_file_handler]
class = FileHandler
level = DEBUG
formatter = file_formatter
args = ('/opt/PrescPipeline/src/python/logs/run_pipeline.log', 'a')

[formatter_file_formatter]
format = %(asctime)s - %(name)s - %(levelname)s - %(message)s
datefmt = "%d-%b-%y %H:%M:%S"